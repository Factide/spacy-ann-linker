{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"spaCy ANN Linker, a pipeline component for generating spaCy KnowledgeBase Alias Candidates for Entity Linking. Documentation : https://microsoft.github.io/spacy-ann-linker Source Code : https://github.com/microsoft/spacy-ann-linker spaCy ANN Linker is a spaCy a pipeline component for generating alias candidates for spaCy entities in doc.ents . It provides an optional interface for linking ambiguous aliases based on descriptions for each entity. The key features are: Easy spaCy Integration : spaCy ANN Linker provides completely serializable spaCy pipeline components that integrate directly into your existing spaCy model. CLI for simple Index Creation : Simply run spacy_ann create_index with your data to create an Approximate Nearest Neighbors index from your data, make an ann_linker pipeline component and save a spaCy model. Built in Web API for easy deployment and Batch Entity Linking queries Requirements \u00b6 Python 3.6+ spaCy ANN Linker is convenient wrapper built on a few comprehensive, high-performing packages. spaCy nmslib (ANN Index) scikit-learn (TF-IDF) . FastAPI (Web Service) . Installation \u00b6 $ pip install spacy-ann-linker ---> 100% Successfully installed spacy-ann-linker Data Prerequisites \u00b6 To use this spaCy ANN Linker you need pre-existing Knowledge Base data. spaCy ANN Linker expects data to exist in 2 JSONL files together in a directory kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl For testing the package, you can use the example data in examples/tutorial/data examples/tutorial/data \u2502 aliases.jsonl \u2502 entities.jsonl entities.jsonl Record Format \u00b6 { \"id\" : \"Canonical Entity Id\" , \"description\" : \"Entity Description used for Disambiguation\" } Example data { \"id\" : \"a1\" , \"description\" : \"Machine learning (ML) is the scientific study of algorithms and statistical models...\" } { \"id\" : \"a2\" , \"description\" : \"ML (\\\"Meta Language\\\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \\\"Lisp with types\\\".\" } { \"id\" : \"a3\" , \"description\" : \"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\" } { \"id\" : \"a4\" , \"description\" : \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States in the 1970s.\" } ... aliases.jsonl Record Format \u00b6 { \"alias\" : \"alias string\" , \"entities\" : [ \"list\" , \"of\" , \"entity\" , \"ids\" ], \"probabilities\" : [ 0.5 , 0.5 ]} Example data { \"alias\" : \"ML\" , \"entities\" : [ \"a1\" , \"a2\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Machine learning\" , \"entities\" : [ \"a1\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Meta Language\" , \"entities\" : [ \"a2\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"NLP\" , \"entities\" : [ \"a3\" , \"a4\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Natural language processing\" , \"entities\" : [ \"a3\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Neuro-linguistic programming\" , \"entities\" : [ \"a4\" ], \"probabilities\" : [ 1.0 ]} ... spaCy prerequisites \u00b6 If you don't have a pretrained spaCy model, download one now. The model needs to have vectors so download a model bigger than en_core_web_sm $ spacy download en_core_web_md ---> 100% Successfully installed en_core_web_md Follow the Tutorial \u00b6 Once you have the Data and spaCy prerequisites completed follow along with the Tutorial to for a step-by-step guide for using the spacy_ann package. License \u00b6 This project is licensed under the terms of the MIT license.","title":"Introduction"},{"location":"#requirements","text":"Python 3.6+ spaCy ANN Linker is convenient wrapper built on a few comprehensive, high-performing packages. spaCy nmslib (ANN Index) scikit-learn (TF-IDF) . FastAPI (Web Service) .","title":"Requirements"},{"location":"#installation","text":"$ pip install spacy-ann-linker ---> 100% Successfully installed spacy-ann-linker","title":"Installation"},{"location":"#data-prerequisites","text":"To use this spaCy ANN Linker you need pre-existing Knowledge Base data. spaCy ANN Linker expects data to exist in 2 JSONL files together in a directory kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl For testing the package, you can use the example data in examples/tutorial/data examples/tutorial/data \u2502 aliases.jsonl \u2502 entities.jsonl","title":"Data Prerequisites"},{"location":"#entitiesjsonl-record-format","text":"{ \"id\" : \"Canonical Entity Id\" , \"description\" : \"Entity Description used for Disambiguation\" } Example data { \"id\" : \"a1\" , \"description\" : \"Machine learning (ML) is the scientific study of algorithms and statistical models...\" } { \"id\" : \"a2\" , \"description\" : \"ML (\\\"Meta Language\\\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \\\"Lisp with types\\\".\" } { \"id\" : \"a3\" , \"description\" : \"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\" } { \"id\" : \"a4\" , \"description\" : \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States in the 1970s.\" } ...","title":"entities.jsonl Record Format"},{"location":"#aliasesjsonl-record-format","text":"{ \"alias\" : \"alias string\" , \"entities\" : [ \"list\" , \"of\" , \"entity\" , \"ids\" ], \"probabilities\" : [ 0.5 , 0.5 ]} Example data { \"alias\" : \"ML\" , \"entities\" : [ \"a1\" , \"a2\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Machine learning\" , \"entities\" : [ \"a1\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Meta Language\" , \"entities\" : [ \"a2\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"NLP\" , \"entities\" : [ \"a3\" , \"a4\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Natural language processing\" , \"entities\" : [ \"a3\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Neuro-linguistic programming\" , \"entities\" : [ \"a4\" ], \"probabilities\" : [ 1.0 ]} ...","title":"aliases.jsonl Record Format"},{"location":"#spacy-prerequisites","text":"If you don't have a pretrained spaCy model, download one now. The model needs to have vectors so download a model bigger than en_core_web_sm $ spacy download en_core_web_md ---> 100% Successfully installed en_core_web_md","title":"spaCy prerequisites"},{"location":"#follow-the-tutorial","text":"Once you have the Data and spaCy prerequisites completed follow along with the Tutorial to for a step-by-step guide for using the spacy_ann package.","title":"Follow the Tutorial"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License"},{"location":"contributing/","text":"Contributing \u00b6 This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Development - Contributing"},{"location":"contributing/#contributing","text":"This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contributing"},{"location":"release-notes/","text":"0.0.2 \u00b6 Add initial version of code, docs, etc. 0.0.1 \u00b6 First commit. Publish to PyPI to reserve package name.","title":"Release Notes"},{"location":"release-notes/#002","text":"Add initial version of code, docs, etc.","title":"0.0.2"},{"location":"release-notes/#001","text":"First commit. Publish to PyPI to reserve package name.","title":"0.0.1"},{"location":"tutorial/create_index/","text":"Tutorial - Create an ANN Index \u00b6 Once you have your data in the supported format, and a spaCy model with vectors you can use the spacy_ann CLI to compute the nearest neighbors index for your Aliases and tran an Encoder for disambiguating entity spans to their canonical Id Run the create_index help command to understand the required arguments. $ spacy_ann create_index --help spacy_ann create_index --help Usage: spacy_ann create_index [OPTIONS] MODEL KB_DIR OUTPUT_DIR Create an AnnLinker based on the Character N-Gram TF- IDF vectors for aliases in a KnowledgeBase model (str): spaCy language model directory or name to load kb_dir (Path): path to the directory with kb entities.jsonl and aliases.jsonl files output_dir (Path): path to output_dir for spaCy model with ann_linker pipe kb File Formats e.g. entities.jsonl {\"id\": \"a1\", \"description\": \"Machine learning (ML) is the scientific study of algorithms and statistical models...\"} {\"id\": \"a2\", \"description\": \"ML (\"Meta Language\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \"Lisp with types\".\"} e.g. aliases.jsonl {\"alias\": \"ML\", \"entities\": [\"a1\", \"a2\"], \"probabilities\": [0.5, 0.5]} Options: --new-model-name TEXT --cg-threshold FLOAT --n-iter INTEGER --verbose / --no-verbose --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Now provide the required arguments. I'm using the example data but at this step use your own. the create_index command will run a few steps and you should see an output like the one below. spacy_ann create_index en_core_web_md examples/tutorial/data examples/tutorial/models // The create_index command runs a few steps // Load the model passed as the first positional argument (en_core_web_md) ===================== Load Model ====================== \u2839 Loading model en_core_web_md\u2714 Done. \u2139 0 entities without a description // Train an EntityEncoder on the descriptions of each Entity ================= Train EntityEncoder ================= \u2838 Starting training EntityEncoder\u2714 Done Training // Apply the EntityEncoder to get the final vectors for each entity ================= Apply EntityEncoder ================= \u2819 Applying EntityEncoder to descriptions\u2714 Finished, embeddings created \u2714 Done adding entities and aliases to kb // Create Nearest Neighbors index from the Aliases in kb_dir/aliases.jsonl ================== Create ANN Index =================== Fitting tfidf vectorizer on 6 aliases Fitting and saving vectorizer took 0.012949 seconds Finding empty (all zeros) tfidf vectors Deleting 2/6 aliases because their tfidf is empty Fitting ann index on 4 aliases 0% 10 20 30 40 50 60 70 80 90 100% |----|----|----|----|----|----|----|----|----|----| *************************************************** Fitting ann index took 0.030826 seconds","title":"Create an Index"},{"location":"tutorial/create_index/#tutorial-create-an-ann-index","text":"Once you have your data in the supported format, and a spaCy model with vectors you can use the spacy_ann CLI to compute the nearest neighbors index for your Aliases and tran an Encoder for disambiguating entity spans to their canonical Id Run the create_index help command to understand the required arguments. $ spacy_ann create_index --help spacy_ann create_index --help Usage: spacy_ann create_index [OPTIONS] MODEL KB_DIR OUTPUT_DIR Create an AnnLinker based on the Character N-Gram TF- IDF vectors for aliases in a KnowledgeBase model (str): spaCy language model directory or name to load kb_dir (Path): path to the directory with kb entities.jsonl and aliases.jsonl files output_dir (Path): path to output_dir for spaCy model with ann_linker pipe kb File Formats e.g. entities.jsonl {\"id\": \"a1\", \"description\": \"Machine learning (ML) is the scientific study of algorithms and statistical models...\"} {\"id\": \"a2\", \"description\": \"ML (\"Meta Language\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \"Lisp with types\".\"} e.g. aliases.jsonl {\"alias\": \"ML\", \"entities\": [\"a1\", \"a2\"], \"probabilities\": [0.5, 0.5]} Options: --new-model-name TEXT --cg-threshold FLOAT --n-iter INTEGER --verbose / --no-verbose --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Now provide the required arguments. I'm using the example data but at this step use your own. the create_index command will run a few steps and you should see an output like the one below. spacy_ann create_index en_core_web_md examples/tutorial/data examples/tutorial/models // The create_index command runs a few steps // Load the model passed as the first positional argument (en_core_web_md) ===================== Load Model ====================== \u2839 Loading model en_core_web_md\u2714 Done. \u2139 0 entities without a description // Train an EntityEncoder on the descriptions of each Entity ================= Train EntityEncoder ================= \u2838 Starting training EntityEncoder\u2714 Done Training // Apply the EntityEncoder to get the final vectors for each entity ================= Apply EntityEncoder ================= \u2819 Applying EntityEncoder to descriptions\u2714 Finished, embeddings created \u2714 Done adding entities and aliases to kb // Create Nearest Neighbors index from the Aliases in kb_dir/aliases.jsonl ================== Create ANN Index =================== Fitting tfidf vectorizer on 6 aliases Fitting and saving vectorizer took 0.012949 seconds Finding empty (all zeros) tfidf vectors Deleting 2/6 aliases because their tfidf is empty Fitting ann index on 4 aliases 0% 10 20 30 40 50 60 70 80 90 100% |----|----|----|----|----|----|----|----|----|----| *************************************************** Fitting ann index took 0.030826 seconds","title":"Tutorial - Create an ANN Index"},{"location":"tutorial/local_entity_linking/","text":"Tutorial - Local Entity Linking \u00b6 In the previous step, you ran the spacy_ann create_index CLI command. The output of this command is a loadable spaCy model with an ann_linker capable of Entity Linking against your KnowledgeBase data. You can load the saved model from output_dir in the previous step just like you would any normal spaCy model. import spacy from spacy.tokens import Span # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning","title":"Local Entity Linking"},{"location":"tutorial/local_entity_linking/#tutorial-local-entity-linking","text":"In the previous step, you ran the spacy_ann create_index CLI command. The output of this command is a loadable spaCy model with an ann_linker capable of Entity Linking against your KnowledgeBase data. You can load the saved model from output_dir in the previous step just like you would any normal spaCy model. import spacy from spacy.tokens import Span # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning","title":"Tutorial - Local Entity Linking"},{"location":"tutorial/remote_entity_linking/","text":"Tutorial - Remote Entity Linking \u00b6 Introduction \u00b6 The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: https://fastapi.tiangolo.com/ The full code for this tutorial is in examples/api This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction The actual webservice service implementation is quite short thanks to FastAPI taking away a lot of the normal boilerplate. Load the model \u00b6 First we need to load our spaCy model from the create_index command. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res Define the batch linking route \u00b6 Once we have our basic API configured and our model loaded, we need a route where we can query the index. Let's add the /link route. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res Now this might seem a bit complicated if you haven't used FastAPI before. However, it's quite simple once you delve into the models. FastAPI leverages Pydantic for serializing and deserializing JSON requests. So at the route level, you pass a response_model and a definition of what the Post Body should look like based on Pydantic models. Models \u00b6 Let's hop over to our models.py file to get a look at the models our route expects. from typing import List from pydantic import BaseModel class LinkingSpan ( BaseModel ): text : str start : int end : int label : str id : str = None class LinkingRecord ( BaseModel ): spans : List [ LinkingSpan ] context : str class LinkingRequest ( BaseModel ): documents : List [ LinkingRecord ] class LinkingResponse ( BaseModel ): documents : List [ LinkingRecord ] If you follow the nested structure of these models you can construct the JSON tree request structure that the API expects as well as the definiton of what it will return. But we've also included an example_request.json file for a real world example. Example Request \u00b6 { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. Let's hop back over to our main app.py and review our /link route again. The logic here is we loop through each document in the request body, make the text into a spaCy Doc object, set the doc.ents based on the provided spans and then run the ann_linker pipe on the doc. We then write to the id attribute of each LinkingSpan object the value of the ent.kb_id_ set by the ann_linker pipeline component. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res Build and Run \u00b6 Now that we have an understanding of the code for the Web Service, let's run it using uvicorn. 1. Install Requirements \u00b6 $ cd examples/api $ pip install -r requirements.txt ---> 100% Successfully installed requirements 2. Start the Web Service \u00b6 $ uvicorn app:app --port 8080 Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit) If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } Call the Web Service \u00b6 Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The RemoteAnnLinker component handles this interaction. Load Extraction Model \u00b6 First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Create a remote_ann_linker pipe \u00b6 Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're still running the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Run the pipeline \u00b6 Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Conclusion \u00b6 This Web Service is quite simple for the tutorial. It skips over things like a health check url, Docker/Kubernetes based deployment, etc. It's merely meant as a quick guide to illustrate the problem this package was originally designed to solve.","title":"Remote Entity Linking"},{"location":"tutorial/remote_entity_linking/#tutorial-remote-entity-linking","text":"","title":"Tutorial - Remote Entity Linking"},{"location":"tutorial/remote_entity_linking/#introduction","text":"The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: https://fastapi.tiangolo.com/ The full code for this tutorial is in examples/api This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction The actual webservice service implementation is quite short thanks to FastAPI taking away a lot of the normal boilerplate.","title":"Introduction"},{"location":"tutorial/remote_entity_linking/#load-the-model","text":"First we need to load our spaCy model from the create_index command. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res","title":"Load the model"},{"location":"tutorial/remote_entity_linking/#define-the-batch-linking-route","text":"Once we have our basic API configured and our model loaded, we need a route where we can query the index. Let's add the /link route. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res Now this might seem a bit complicated if you haven't used FastAPI before. However, it's quite simple once you delve into the models. FastAPI leverages Pydantic for serializing and deserializing JSON requests. So at the route level, you pass a response_model and a definition of what the Post Body should look like based on Pydantic models.","title":"Define the batch linking route"},{"location":"tutorial/remote_entity_linking/#models","text":"Let's hop over to our models.py file to get a look at the models our route expects. from typing import List from pydantic import BaseModel class LinkingSpan ( BaseModel ): text : str start : int end : int label : str id : str = None class LinkingRecord ( BaseModel ): spans : List [ LinkingSpan ] context : str class LinkingRequest ( BaseModel ): documents : List [ LinkingRecord ] class LinkingResponse ( BaseModel ): documents : List [ LinkingRecord ] If you follow the nested structure of these models you can construct the JSON tree request structure that the API expects as well as the definiton of what it will return. But we've also included an example_request.json file for a real world example.","title":"Models"},{"location":"tutorial/remote_entity_linking/#example-request","text":"{ \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. Let's hop back over to our main app.py and review our /link route again. The logic here is we loop through each document in the request body, make the text into a spaCy Doc object, set the doc.ents based on the provided spans and then run the ann_linker pipe on the doc. We then write to the id attribute of each LinkingSpan object the value of the ent.kb_id_ set by the ann_linker pipeline component. # Copyright (c) Microsoft Corporation. All rights reserved. # Licensed under the MIT License. import os from dotenv import load_dotenv , find_dotenv from fastapi import FastAPI , Body from starlette.middleware.cors import CORSMiddleware from starlette.responses import RedirectResponse import spacy import uvicorn from models import LinkingRequest , LinkingResponse , LinkingRecord load_dotenv ( find_dotenv ()) prefix = os . getenv ( \"CLUSTER_ROUTE_PREFIX\" ) if not prefix : prefix = \"\" prefix = prefix . rstrip ( \"/\" ) app = FastAPI ( title = \"spacy-ann-linker\" , version = \"1.0\" , description = \"Entity Linking with Approximate Nearest Neighbors index lookup for Aliases\" , openapi_prefix = prefix , ) example_request = list ( srsly . read_json ( './example_request.json' )) nlp = spacy . load ( \"../tutorial/models/ann_linker\" ) @app . get ( \"/\" , include_in_schema = False ) def docs_redirect (): return RedirectResponse ( f \" {prefix} /docs\" ) @app . post ( \"/link\" , response_model = LinkingResponse ) async def link ( body : LinkingRequest = Body ( ... , example = example_request )): \"\"\"Link batch of Spans to their canonical KnowledgeBase Id.\"\"\" res = LinkingResponse ( documents = []) for doc in body . documents : spacy_doc = nlp . make_doc ( doc . context ) spans = [ spacy_doc . char_span ( s . start , s . end , label = s . label ) for s in doc . spans ] spacy_doc . ents = [ s for s in spans if s ] spacy_doc = nlp . get_pipe ( 'ann_linker' )( spacy_doc ) for i , ent in enumerate ( spacy_doc . ents ): doc . spans [ i ] . id = ent . kb_id_ res . documents . append ( LinkingRecord ( spans = doc . spans , context = doc . context ) ) return res","title":"Example Request"},{"location":"tutorial/remote_entity_linking/#build-and-run","text":"Now that we have an understanding of the code for the Web Service, let's run it using uvicorn.","title":"Build and Run"},{"location":"tutorial/remote_entity_linking/#1-install-requirements","text":"$ cd examples/api $ pip install -r requirements.txt ---> 100% Successfully installed requirements","title":"1. Install Requirements"},{"location":"tutorial/remote_entity_linking/#2-start-the-web-service","text":"$ uvicorn app:app --port 8080 Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit) If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] }","title":"2. Start the Web Service"},{"location":"tutorial/remote_entity_linking/#call-the-web-service","text":"Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The RemoteAnnLinker component handles this interaction.","title":"Call the Web Service"},{"location":"tutorial/remote_entity_linking/#load-extraction-model","text":"First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Load Extraction Model"},{"location":"tutorial/remote_entity_linking/#create-a-remote_ann_linker-pipe","text":"Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're still running the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Create a remote_ann_linker pipe"},{"location":"tutorial/remote_entity_linking/#run-the-pipeline","text":"Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Run the pipeline"},{"location":"tutorial/remote_entity_linking/#conclusion","text":"This Web Service is quite simple for the tutorial. It skips over things like a health check url, Docker/Kubernetes based deployment, etc. It's merely meant as a quick guide to illustrate the problem this package was originally designed to solve.","title":"Conclusion"},{"location":"tutorial/remote_entity_linking_new/","text":"Tutorial - Remote Entity Linking \u00b6 Introduction \u00b6 The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using the spacy_ann serve command Internally, the API is built using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: https://fastapi.tiangolo.com/ This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction Prerequisite - Install [api] requirements \u00b6 spacy-ann-linker provides an installation extension for using the serve CLI command called [api] To install the api extension run: $ pip install spacy-ann-linker [ api ] ---> 100% Successfully installed spacy-ann-linker[api] Now you can run the spacy_ann serve command Serve a model remotely \u00b6 In order to serve a model, you need to have already run the create_index command and have as saved spaCy model with an ann_linker pipeline component. If you have this already, you can serve that model using the serve command provided in the CLI. For the example below I'm going to use the example ann_linker model we used in the tutorial. $ spacy_ann serve examples/tutorial/models/ann_linker Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit) Example Request \u00b6 spacy-ann-linker provides an example JSON input request based on the model created with the example tutorial data. This is the request format that the default server accepts. { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } Call the Web Service \u00b6 Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The spacy_ann.remote_ann_linker.RemoteAnnLinker component handles this interaction. The following example code demonstrates the usage of the RemoteAnnLinker . Load Extraction Model \u00b6 First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Create a remote_ann_linker pipe \u00b6 Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're testing the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Run the pipeline \u00b6 Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Conclusion \u00b6 This Web Service is quite simple for the tutorial. It skips over things like a health check url, Docker/Kubernetes based deployment, etc. It's merely meant as a quick guide to illustrate the problem this package was originally designed to solve.","title":"Remote Entity Linking (New)"},{"location":"tutorial/remote_entity_linking_new/#tutorial-remote-entity-linking","text":"","title":"Tutorial - Remote Entity Linking"},{"location":"tutorial/remote_entity_linking_new/#introduction","text":"The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using the spacy_ann serve command Internally, the API is built using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: https://fastapi.tiangolo.com/ This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction","title":"Introduction"},{"location":"tutorial/remote_entity_linking_new/#prerequisite-install-api-requirements","text":"spacy-ann-linker provides an installation extension for using the serve CLI command called [api] To install the api extension run: $ pip install spacy-ann-linker [ api ] ---> 100% Successfully installed spacy-ann-linker[api] Now you can run the spacy_ann serve command","title":"Prerequisite - Install [api] requirements"},{"location":"tutorial/remote_entity_linking_new/#serve-a-model-remotely","text":"In order to serve a model, you need to have already run the create_index command and have as saved spaCy model with an ann_linker pipeline component. If you have this already, you can serve that model using the serve command provided in the CLI. For the example below I'm going to use the example ann_linker model we used in the tutorial. $ spacy_ann serve examples/tutorial/models/ann_linker Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit)","title":"Serve a model remotely"},{"location":"tutorial/remote_entity_linking_new/#example-request","text":"spacy-ann-linker provides an example JSON input request based on the model created with the example tutorial data. This is the request format that the default server accepts. { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] }","title":"Example Request"},{"location":"tutorial/remote_entity_linking_new/#call-the-web-service","text":"Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The spacy_ann.remote_ann_linker.RemoteAnnLinker component handles this interaction. The following example code demonstrates the usage of the RemoteAnnLinker .","title":"Call the Web Service"},{"location":"tutorial/remote_entity_linking_new/#load-extraction-model","text":"First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Load Extraction Model"},{"location":"tutorial/remote_entity_linking_new/#create-a-remote_ann_linker-pipe","text":"Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're testing the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Create a remote_ann_linker pipe"},{"location":"tutorial/remote_entity_linking_new/#run-the-pipeline","text":"Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Run the pipeline"},{"location":"tutorial/remote_entity_linking_new/#conclusion","text":"This Web Service is quite simple for the tutorial. It skips over things like a health check url, Docker/Kubernetes based deployment, etc. It's merely meant as a quick guide to illustrate the problem this package was originally designed to solve.","title":"Conclusion"}]}