{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"spaCy ANN Linker, a pipeline component for generating spaCy KnowledgeBase Alias Candidates for Entity Linking based on an Approximate Nearest Neighbors (ANN) index computed on the Character N-Gram TF-IDF representation of all aliases in your KnowledgeBase. Documentation : https://microsoft.github.io/spacy-ann-linker Source Code : https://github.com/microsoft/spacy-ann-linker spaCy ANN Linker is a spaCy a pipeline component for generating alias candidates for spaCy entities in doc.ents . It provides an optional interface for linking ambiguous aliases based on descriptions for each entity. The key features are: Easy spaCy Integration : spaCy ANN Linker provides completely serializable spaCy pipeline components that integrate directly into your existing spaCy model. CLI for simple Index Creation : Simply run spacy_ann create_index with your data to create an Approximate Nearest Neighbors index from your data, make an ann_linker pipeline component and save a spaCy model. Built in Web API for easy deployment and Batch Entity Linking queries Requirements \u00b6 Python 3.6+ spaCy ANN Linker is convenient wrapper built on a few comprehensive, high-performing packages. spaCy nmslib (ANN Index) scikit-learn (TF-IDF) . FastAPI (Web Service) . Installation \u00b6 $ pip install spacy-ann-linker ---> 100% Successfully installed spacy-ann-linker Data Prerequisites \u00b6 To use this spaCy ANN Linker you need pre-existing Knowledge Base data. spaCy ANN Linker expects data to exist in 2 JSONL files together in a directory kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl For testing the package, you can use the example data in examples/tutorial/data examples/tutorial/data \u2502 aliases.jsonl \u2502 entities.jsonl entities.jsonl Record Format \u00b6 { \"id\" : \"Canonical Entity Id\" , \"description\" : \"Entity Description used for Disambiguation\" } Example data { \"id\" : \"a1\" , \"description\" : \"Machine learning (ML) is the scientific study of algorithms and statistical models...\" } { \"id\" : \"a2\" , \"description\" : \"ML (\\\"Meta Language\\\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \\\"Lisp with types\\\".\" } { \"id\" : \"a3\" , \"description\" : \"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\" } { \"id\" : \"a4\" , \"description\" : \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States in the 1970s.\" } ... aliases.jsonl Record Format \u00b6 { \"alias\" : \"alias string\" , \"entities\" : [ \"list\" , \"of\" , \"entity\" , \"ids\" ], \"probabilities\" : [ 0.5 , 0.5 ]} Example data { \"alias\" : \"ML\" , \"entities\" : [ \"a1\" , \"a2\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Machine learning\" , \"entities\" : [ \"a1\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Meta Language\" , \"entities\" : [ \"a2\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"NLP\" , \"entities\" : [ \"a3\" , \"a4\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Natural language processing\" , \"entities\" : [ \"a3\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Neuro-linguistic programming\" , \"entities\" : [ \"a4\" ], \"probabilities\" : [ 1.0 ]} ... Example Data \u00b6 spacy-ann-linker comes with some example data to get you started. Important If this is your first time using spacy-ann-linker start out with the example data using the spacy_ann example_data command. Just pass an output_dir to write the example data to. $ spacy_ann example_data ./kb =============== Example Data ================ Writing Example data to test/kb \u2714 Done. This should leave you with a folder called ./kb_dir that has a structure like kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl spaCy prerequisites \u00b6 If you don't have a pretrained spaCy model, download one now. The model needs to have vectors so download a model bigger than en_core_web_sm $ spacy download en_core_web_md ---> 100% Successfully installed en_core_web_md Next Steps \u00b6 Once you have the Data and spaCy prerequisites completed follow along with the Tutorial to for a step-by-step guide for using the spacy_ann package. Important These are just the prerequisites. Follow the full tutorial linked above for a step-by-step guide to working with spacy-ann-linker . License \u00b6 This project is licensed under the terms of the MIT license.","title":"Introduction"},{"location":"#requirements","text":"Python 3.6+ spaCy ANN Linker is convenient wrapper built on a few comprehensive, high-performing packages. spaCy nmslib (ANN Index) scikit-learn (TF-IDF) . FastAPI (Web Service) .","title":"Requirements"},{"location":"#installation","text":"$ pip install spacy-ann-linker ---> 100% Successfully installed spacy-ann-linker","title":"Installation"},{"location":"#data-prerequisites","text":"To use this spaCy ANN Linker you need pre-existing Knowledge Base data. spaCy ANN Linker expects data to exist in 2 JSONL files together in a directory kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl For testing the package, you can use the example data in examples/tutorial/data examples/tutorial/data \u2502 aliases.jsonl \u2502 entities.jsonl","title":"Data Prerequisites"},{"location":"#entitiesjsonl-record-format","text":"{ \"id\" : \"Canonical Entity Id\" , \"description\" : \"Entity Description used for Disambiguation\" } Example data { \"id\" : \"a1\" , \"description\" : \"Machine learning (ML) is the scientific study of algorithms and statistical models...\" } { \"id\" : \"a2\" , \"description\" : \"ML (\\\"Meta Language\\\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \\\"Lisp with types\\\".\" } { \"id\" : \"a3\" , \"description\" : \"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\" } { \"id\" : \"a4\" , \"description\" : \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States in the 1970s.\" } ...","title":"entities.jsonl Record Format"},{"location":"#aliasesjsonl-record-format","text":"{ \"alias\" : \"alias string\" , \"entities\" : [ \"list\" , \"of\" , \"entity\" , \"ids\" ], \"probabilities\" : [ 0.5 , 0.5 ]} Example data { \"alias\" : \"ML\" , \"entities\" : [ \"a1\" , \"a2\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Machine learning\" , \"entities\" : [ \"a1\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Meta Language\" , \"entities\" : [ \"a2\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"NLP\" , \"entities\" : [ \"a3\" , \"a4\" ], \"probabilities\" : [ 0.5 , 0.5 ]} { \"alias\" : \"Natural language processing\" , \"entities\" : [ \"a3\" ], \"probabilities\" : [ 1.0 ]} { \"alias\" : \"Neuro-linguistic programming\" , \"entities\" : [ \"a4\" ], \"probabilities\" : [ 1.0 ]} ...","title":"aliases.jsonl Record Format"},{"location":"#example-data","text":"spacy-ann-linker comes with some example data to get you started. Important If this is your first time using spacy-ann-linker start out with the example data using the spacy_ann example_data command. Just pass an output_dir to write the example data to. $ spacy_ann example_data ./kb =============== Example Data ================ Writing Example data to test/kb \u2714 Done. This should leave you with a folder called ./kb_dir that has a structure like kb_dir \u2502 aliases.jsonl \u2502 entities.jsonl","title":"Example Data"},{"location":"#spacy-prerequisites","text":"If you don't have a pretrained spaCy model, download one now. The model needs to have vectors so download a model bigger than en_core_web_sm $ spacy download en_core_web_md ---> 100% Successfully installed en_core_web_md","title":"spaCy prerequisites"},{"location":"#next-steps","text":"Once you have the Data and spaCy prerequisites completed follow along with the Tutorial to for a step-by-step guide for using the spacy_ann package. Important These are just the prerequisites. Follow the full tutorial linked above for a step-by-step guide to working with spacy-ann-linker .","title":"Next Steps"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License"},{"location":"contributing/","text":"Contributing \u00b6 This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Development - Contributing"},{"location":"contributing/#contributing","text":"This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Contributing"},{"location":"release-notes/","text":"0.0.2 \u00b6 Add initial version of code, docs, etc. 0.0.1 \u00b6 First commit. Publish to PyPI to reserve package name.","title":"Release Notes"},{"location":"release-notes/#002","text":"Add initial version of code, docs, etc.","title":"0.0.2"},{"location":"release-notes/#001","text":"First commit. Publish to PyPI to reserve package name.","title":"0.0.1"},{"location":"tutorial/create_index/","text":"Tutorial - Create an ANN Index \u00b6 Once you have your data in the supported format, and a spaCy model with vectors you can use the spacy_ann CLI to compute the nearest neighbors index for your Aliases and tran an Encoder for disambiguating entity spans to their canonical Id Run the create_index help command to understand the required arguments. $ spacy_ann create_index --help spacy_ann create_index --help Usage: spacy_ann create_index [OPTIONS] MODEL KB_DIR OUTPUT_DIR Create an AnnLinker based on the Character N-Gram TF- IDF vectors for aliases in a KnowledgeBase model (str): spaCy language model directory or name to load kb_dir (Path): path to the directory with kb entities.jsonl and aliases.jsonl files output_dir (Path): path to output_dir for spaCy model with ann_linker pipe kb File Formats e.g. entities.jsonl {\"id\": \"a1\", \"description\": \"Machine learning (ML) is the scientific study of algorithms and statistical models...\"} {\"id\": \"a2\", \"description\": \"ML (\"Meta Language\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \"Lisp with types\".\"} e.g. aliases.jsonl {\"alias\": \"ML\", \"entities\": [\"a1\", \"a2\"], \"probabilities\": [0.5, 0.5]} Options: --new-model-name TEXT --cg-threshold FLOAT --n-iter INTEGER --verbose / --no-verbose --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Now provide the required arguments. I'm using the example data but at this step use your own. the create_index command will run a few steps and you should see an output like the one below. spacy_ann create_index en_core_web_md examples/tutorial/data examples/tutorial/models // The create_index command runs a few steps // Load the model passed as the first positional argument (en_core_web_md) ===================== Load Model ====================== \u2839 Loading model en_core_web_md\u2714 Done. \u2139 0 entities without a description // Train an EntityEncoder on the descriptions of each Entity ================= Train EntityEncoder ================= \u2838 Starting training EntityEncoder\u2714 Done Training // Apply the EntityEncoder to get the final vectors for each entity ================= Apply EntityEncoder ================= \u2819 Applying EntityEncoder to descriptions\u2714 Finished, embeddings created \u2714 Done adding entities and aliases to kb // Create Nearest Neighbors index from the Aliases in kb_dir/aliases.jsonl ================== Create ANN Index =================== Fitting tfidf vectorizer on 6 aliases Fitting and saving vectorizer took 0.012949 seconds Finding empty (all zeros) tfidf vectors Deleting 2/6 aliases because their tfidf is empty Fitting ann index on 4 aliases 0% 10 20 30 40 50 60 70 80 90 100% |----|----|----|----|----|----|----|----|----|----| *************************************************** Fitting ann index took 0.030826 seconds","title":"Create an Index"},{"location":"tutorial/create_index/#tutorial-create-an-ann-index","text":"Once you have your data in the supported format, and a spaCy model with vectors you can use the spacy_ann CLI to compute the nearest neighbors index for your Aliases and tran an Encoder for disambiguating entity spans to their canonical Id Run the create_index help command to understand the required arguments. $ spacy_ann create_index --help spacy_ann create_index --help Usage: spacy_ann create_index [OPTIONS] MODEL KB_DIR OUTPUT_DIR Create an AnnLinker based on the Character N-Gram TF- IDF vectors for aliases in a KnowledgeBase model (str): spaCy language model directory or name to load kb_dir (Path): path to the directory with kb entities.jsonl and aliases.jsonl files output_dir (Path): path to output_dir for spaCy model with ann_linker pipe kb File Formats e.g. entities.jsonl {\"id\": \"a1\", \"description\": \"Machine learning (ML) is the scientific study of algorithms and statistical models...\"} {\"id\": \"a2\", \"description\": \"ML (\"Meta Language\") is a general-purpose functional programming language. It has roots in Lisp, and has been characterized as \"Lisp with types\".\"} e.g. aliases.jsonl {\"alias\": \"ML\", \"entities\": [\"a1\", \"a2\"], \"probabilities\": [0.5, 0.5]} Options: --new-model-name TEXT --cg-threshold FLOAT --n-iter INTEGER --verbose / --no-verbose --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. --help Show this message and exit. Now provide the required arguments. I'm using the example data but at this step use your own. the create_index command will run a few steps and you should see an output like the one below. spacy_ann create_index en_core_web_md examples/tutorial/data examples/tutorial/models // The create_index command runs a few steps // Load the model passed as the first positional argument (en_core_web_md) ===================== Load Model ====================== \u2839 Loading model en_core_web_md\u2714 Done. \u2139 0 entities without a description // Train an EntityEncoder on the descriptions of each Entity ================= Train EntityEncoder ================= \u2838 Starting training EntityEncoder\u2714 Done Training // Apply the EntityEncoder to get the final vectors for each entity ================= Apply EntityEncoder ================= \u2819 Applying EntityEncoder to descriptions\u2714 Finished, embeddings created \u2714 Done adding entities and aliases to kb // Create Nearest Neighbors index from the Aliases in kb_dir/aliases.jsonl ================== Create ANN Index =================== Fitting tfidf vectorizer on 6 aliases Fitting and saving vectorizer took 0.012949 seconds Finding empty (all zeros) tfidf vectors Deleting 2/6 aliases because their tfidf is empty Fitting ann index on 4 aliases 0% 10 20 30 40 50 60 70 80 90 100% |----|----|----|----|----|----|----|----|----|----| *************************************************** Fitting ann index took 0.030826 seconds","title":"Tutorial - Create an ANN Index"},{"location":"tutorial/local_entity_linking/","text":"Tutorial - Local Entity Linking \u00b6 In the previous step, you ran the spacy_ann create_index CLI command. The output of this command is a loadable spaCy model with an ann_linker capable of Entity Linking against your KnowledgeBase data. You can load the saved model from output_dir in the previous step just like you would any normal spaCy model. Load ann_linker model \u00b6 First load the model created by spacy_ann create_index import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning Load Extraction Model \u00b6 This is a bit of misnomar for the provided example code. You likely want a trained NER model but the purpose of this example we'll just arbitrarily extract entities using the spaCy EntityRuler component by just add a few terms to it that are close to those in our KnowledgeBase. import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning Test the trained ann_linker component \u00b6 Run the pipeline on some sample text and ensure that you have e.kb_id_ set properly for each entity. You should get id a3 for \"NLP\" and id a1 for \"machine learn import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning Next Steps \u00b6 This works great when you can afford to fit your KnowledgeBase in memory and have full access to your KnowledgeBase. In the next step of this tutorial, we'll talk about hosting the KnowledgeBase and ANN Index remotely and making batch calls to the endpoint so you can keep the KnowledgeBase and model code separate.","title":"Local Entity Linking"},{"location":"tutorial/local_entity_linking/#tutorial-local-entity-linking","text":"In the previous step, you ran the spacy_ann create_index CLI command. The output of this command is a loadable spaCy model with an ann_linker capable of Entity Linking against your KnowledgeBase data. You can load the saved model from output_dir in the previous step just like you would any normal spaCy model.","title":"Tutorial - Local Entity Linking"},{"location":"tutorial/local_entity_linking/#load-ann_linker-model","text":"First load the model created by spacy_ann create_index import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning","title":"Load ann_linker model"},{"location":"tutorial/local_entity_linking/#load-extraction-model","text":"This is a bit of misnomar for the provided example code. You likely want a trained NER model but the purpose of this example we'll just arbitrarily extract entities using the spaCy EntityRuler component by just add a few terms to it that are close to those in our KnowledgeBase. import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning","title":"Load Extraction Model"},{"location":"tutorial/local_entity_linking/#test-the-trained-ann_linker-component","text":"Run the pipeline on some sample text and ensure that you have e.kb_id_ set properly for each entity. You should get id a3 for \"NLP\" and id a1 for \"machine learn import spacy from spacy.tokens import Span if __name__ == \"__main__\" : # Load the spaCy model from the output_dir you used # from the create_index command model_dir = \"examples/tutorial/models/ann_linker\" nlp = spacy . load ( model_dir ) # The NER component of the en_core_web_md model doesn't actually # recognize the aliases as entities so we'll add a # spaCy EntityRuler component for now to extract them. ruler = nlp . create_pipe ( 'entity_ruler' ) patterns = [ { \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in nlp . get_pipe ( 'ann_linker' ) . kb . get_alias_strings () + [ 'machine learn' ] ] ruler . add_patterns ( patterns ) nlp . add_pipe ( ruler , before = \"ann_linker\" ) doc = nlp ( \"NLP is a subset of machine learn.\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('machine learn', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learning","title":"Test the trained ann_linker component"},{"location":"tutorial/local_entity_linking/#next-steps","text":"This works great when you can afford to fit your KnowledgeBase in memory and have full access to your KnowledgeBase. In the next step of this tutorial, we'll talk about hosting the KnowledgeBase and ANN Index remotely and making batch calls to the endpoint so you can keep the KnowledgeBase and model code separate.","title":"Next Steps"},{"location":"tutorial/remote_entity_linking/","text":"Tutorial - Remote Entity Linking \u00b6 Introduction \u00b6 The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using the spacy_ann serve command Tip Internally, the API is built using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: FastAPI Note This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction sequenceDiagram participant client as Client participant net as Network Boundary participant service as Remote Service Note over client,service: Input Text: \"NLP is a subset of Machine learning.\" Note over service: Serve ANN Linker Note over client: Extract Entities opt Entity Linking client ->> service: Send Extracted Entities from Client Note over service: Run ANN Linking service -->> client: Return Linked Entity Ids end Prerequisite - Install [api] requirements \u00b6 spacy-ann-linker provides an installation extension for using the serve CLI command called [api] To install the api extension run: $ pip install spacy-ann-linker [ api ] ---> 100% Successfully installed spacy-ann-linker[api] Now you can run the spacy_ann serve command Serve a model remotely \u00b6 In order to serve a model, you need to have already run the create_index command and have as saved spaCy model with an ann_linker pipeline component. If you have this already, you can serve that model using the serve command provided in the CLI. For the example below I'm going to use the example ann_linker model we used in the tutorial. $ spacy_ann serve examples/tutorial/models/ann_linker Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit) Example Request \u00b6 spacy-ann-linker provides an example JSON input request based on the model created with the example tutorial data. This is the request format that the default server accepts. { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } Call the Web Service \u00b6 Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The spacy_ann.remote_ann_linker.RemoteAnnLinker component handles this interaction. The following example code demonstrates the usage of the RemoteAnnLinker . Load Extraction Model \u00b6 First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Create a remote_ann_linker pipe \u00b6 Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're testing the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Run the pipeline \u00b6 Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin Serving in Production \u00b6 The default service run with spacy_ann serve uses Uvicorn . For production usage, it's recommended to use a process manager like Gunicorn using the uvicorn.workers.UvicornWorker . This functionality is built into spacy-ann-linker directly. Just use the --use-gunicorn flag when running spacy_ann serve and add parameters for the number of workers and bind to the host 0.0.0.0 so the service can be reached on a remote server. $ spacy_ann serve examples/tutorial/models/ann_linker --use-gunicorn --n-workers 2 --host 0 .0.0.0 [2020-02-20 11:03:45] [7064] Starting gunicorn 20.0.4 [2020-02-20 11:03:45] [7064] Listening at: http://0.0.0.0:8080 (7064) [2020-02-20 11:03:45] [7064] Using worker: uvicorn.workers.UvicornWorker [2020-02-20 11:03:46] [7075] Booting worker with pid: 7075 [2020-02-20 11:03:46] [7076] Booting worker with pid: 7076 [2020-02-20 11:03:46] [7075] Started server process [7075] [2020-02-20 11:03:46] [7076] Started server process [7076] [2020-02-20 11:03:46] [7075] Waiting for application startup. [2020-02-20 11:03:46] [7076] Waiting for application startup. [2020-02-20 11:03:46] [7075] Application startup complete. [2020-02-20 11:03:46] [7076] Application startup complete. Note If you don't provide the --n-workers argument, it will default to 2 workers per CPU core + 1. This is generally the recommended approach from Gunicorn but may not work well for your use case. Play around with this number based on the hardware and usage patterns to get the optimal configuration. Conclusion \u00b6 Now you can effectively serve an instance of a spacy-ann-linker model in production and have the ability to remotely call that service directly from the remote_ann_linker spaCy pipeline component.","title":"Remote Entity Linking"},{"location":"tutorial/remote_entity_linking/#tutorial-remote-entity-linking","text":"","title":"Tutorial - Remote Entity Linking"},{"location":"tutorial/remote_entity_linking/#introduction","text":"The original reason for developing this package at Microsoft is we need a way to Link Entities to a KnowledgeBase without having that KnowledgeBase in memory. This tutorial walks through creating the ANN Index for all the Aliases in a KnowledgeBase remotely and exposing the index through a Web Service using the spacy_ann serve command Tip Internally, the API is built using FastAPI. If you're unfamiliar with FastAPI, you can read more about it here: FastAPI Note This tutorial assumes you've already run the create_index command and have a saved model. If you haven't already done that, follow the steps in the Introduction sequenceDiagram participant client as Client participant net as Network Boundary participant service as Remote Service Note over client,service: Input Text: \"NLP is a subset of Machine learning.\" Note over service: Serve ANN Linker Note over client: Extract Entities opt Entity Linking client ->> service: Send Extracted Entities from Client Note over service: Run ANN Linking service -->> client: Return Linked Entity Ids end","title":"Introduction"},{"location":"tutorial/remote_entity_linking/#prerequisite-install-api-requirements","text":"spacy-ann-linker provides an installation extension for using the serve CLI command called [api] To install the api extension run: $ pip install spacy-ann-linker [ api ] ---> 100% Successfully installed spacy-ann-linker[api] Now you can run the spacy_ann serve command","title":"Prerequisite - Install [api] requirements"},{"location":"tutorial/remote_entity_linking/#serve-a-model-remotely","text":"In order to serve a model, you need to have already run the create_index command and have as saved spaCy model with an ann_linker pipeline component. If you have this already, you can serve that model using the serve command provided in the CLI. For the example below I'm going to use the example ann_linker model we used in the tutorial. $ spacy_ann serve examples/tutorial/models/ann_linker Started server process [21052] Waiting for application startup. Application startup complete. Uvicorn running on http://127.0.0.1:8080 (Press CTRL+C to quit)","title":"Serve a model remotely"},{"location":"tutorial/remote_entity_linking/#example-request","text":"spacy-ann-linker provides an example JSON input request based on the model created with the example tutorial data. This is the request format that the default server accepts. { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] } From this request, you can see that we're passing the Entity Spans extracted by an NER model along with the context in which they were extracted. This is all the input data we need for the ann_linker component to be able to identify candidate aliases and disambiguate and alias to a cononical entity id. If you open your browser to http://localhost:8080 now you'll be automatically redirected to the /docs route and greeted with the Open API UI for the Web Service Now if you click on the green highlighted link route, click the button that says \"Try it out\" and hit Execute, you'll be making a request with the example_request.json data and should get a JSON reponse back that looks like: { \"documents\" : [ { \"spans\" : [ { \"text\" : \"NLP\" , \"start\" : 0 , \"end\" : 3 , \"label\" : \"SKILL\" , \"id\" : \"a3\" }, { \"text\" : \"researched\" , \"start\" : 16 , \"end\" : 26 , \"label\" : \"SKILL\" , \"id\" : \"a15\" }, { \"text\" : \"Machine learning\" , \"start\" : 37 , \"end\" : 53 , \"label\" : \"SKILL\" , \"id\" : \"a1\" } ], \"context\" : \"NLP is a highly researched subset of Machine learning.\" } ] }","title":"Example Request"},{"location":"tutorial/remote_entity_linking/#call-the-web-service","text":"Now that we have an understanding of the remote web service, we need an easy way to call this service from a normal spaCy pipeline. The spacy_ann.remote_ann_linker.RemoteAnnLinker component handles this interaction. The following example code demonstrates the usage of the RemoteAnnLinker .","title":"Call the Web Service"},{"location":"tutorial/remote_entity_linking/#load-extraction-model","text":"First, load a model capable of extracting the Entities in your KnowledgeBase. This could be a trained NER model or a rule based extraction or a combination of both. For simplicity we'll use the spaCy EntityRuler component and just add a few terms to it that are close to those in our KnowledgeBase. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Load Extraction Model"},{"location":"tutorial/remote_entity_linking/#create-a-remote_ann_linker-pipe","text":"Now create a remote_ann_linker pipe using nlp.create_pipe and set the base_url config value to the batch linking url of your web service. If you're testing the service locally from the last step this should be http://localhost:8080/link import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Create a remote_ann_linker pipe"},{"location":"tutorial/remote_entity_linking/#run-the-pipeline","text":"Now you can call the pipeline the exact same way as you did in when using the local ann_linker component and you should get the exact same results. import spacy if __name__ == \"__main__\" : nlp = spacy . blank ( \"en\" ) aliases = [ 'machine learning' , 'ML' , 'NLP' , 'researched' ] ruler = nlp . create_pipe ( 'entity_ruler' , { \"overwrite_ents\" : True }) patterns = [{ \"label\" : \"SKILL\" , \"pattern\" : alias } for alias in aliases ] ruler . add_patterns ( patterns ) remote_ann_linker = nlp . create_pipe ( 'remote_ann_linker' , { 'base_url' : \"http://localhost:8080/link\" }) nlp . add_pipe ( remote_ann_linker ) doc = nlp ( \"NLP is a highly researched area of machine learning\" ) print ([( e . text , e . label_ , e . kb_id_ ) for e in doc . ents ]) # Outputs: # [('NLP', 'SKILL', 'a3'), ('Machine learning', 'SKILL', 'a1')] # # In our entities.jsonl file # a3 => Natural Language Processing # a1 => Machine learnin","title":"Run the pipeline"},{"location":"tutorial/remote_entity_linking/#serving-in-production","text":"The default service run with spacy_ann serve uses Uvicorn . For production usage, it's recommended to use a process manager like Gunicorn using the uvicorn.workers.UvicornWorker . This functionality is built into spacy-ann-linker directly. Just use the --use-gunicorn flag when running spacy_ann serve and add parameters for the number of workers and bind to the host 0.0.0.0 so the service can be reached on a remote server. $ spacy_ann serve examples/tutorial/models/ann_linker --use-gunicorn --n-workers 2 --host 0 .0.0.0 [2020-02-20 11:03:45] [7064] Starting gunicorn 20.0.4 [2020-02-20 11:03:45] [7064] Listening at: http://0.0.0.0:8080 (7064) [2020-02-20 11:03:45] [7064] Using worker: uvicorn.workers.UvicornWorker [2020-02-20 11:03:46] [7075] Booting worker with pid: 7075 [2020-02-20 11:03:46] [7076] Booting worker with pid: 7076 [2020-02-20 11:03:46] [7075] Started server process [7075] [2020-02-20 11:03:46] [7076] Started server process [7076] [2020-02-20 11:03:46] [7075] Waiting for application startup. [2020-02-20 11:03:46] [7076] Waiting for application startup. [2020-02-20 11:03:46] [7075] Application startup complete. [2020-02-20 11:03:46] [7076] Application startup complete. Note If you don't provide the --n-workers argument, it will default to 2 workers per CPU core + 1. This is generally the recommended approach from Gunicorn but may not work well for your use case. Play around with this number based on the hardware and usage patterns to get the optimal configuration.","title":"Serving in Production"},{"location":"tutorial/remote_entity_linking/#conclusion","text":"Now you can effectively serve an instance of a spacy-ann-linker model in production and have the ability to remotely call that service directly from the remote_ann_linker spaCy pipeline component.","title":"Conclusion"}]}